{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Significance of Correlation Coefficients\n",
    "\n",
    "## When $\\rho$ = 0:\n",
    "\n",
    "When $\\rho$ = 0, we can use a form of the $z$-statistic and $t$-statistic.\n",
    "\n",
    "$$\n",
    "t = \\frac{r - \\rho}{\\sqrt{\\frac{1-r^2}{N-2}}}\n",
    "$$\n",
    "\n",
    "where the standard error of the distribution of $r$ is $\\sqrt{\\frac{1-r^2}{N-2}}$ and $\\rho$ = 0.\n",
    "\n",
    "For large $N$, this statistic is normally distributed (like the $z$-statistic), but for small $N$ it has the distribution like a $t$-statistic, with $\\nu$ = $N$ - 2 degrees of freedom. \n",
    "\n",
    "As before, for small $N$ the above statistic is only valid if the underlying distributions of the variables being correlated are normal. If $N$ is large, then the Central Limit Theorem applies and the underlying distributions do not need to be normal.\n",
    "\n",
    "\n",
    "Let's take a look at an example:\n",
    "\n",
    "```{admonition} Question #1\n",
    ":class: tip\n",
    "We have two time series, each of length 20, and they are correlated at $r$ = 0.6. Does this correlation exceed the 95\\% confidence interval under the null hypothesis that $\\rho$ = 0? You can assume both time series are sampled from underlying normal distributions.\n",
    "```\n",
    "\n",
    "We had no prior knowledge (before getting the samples) that the sample correlation would be positive or negative, so we will use a two-sided $t$-test. The critial $t$-value for the 95\\% confidence level when dof = $N$ - 2 = 18 is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1\n"
     ]
    }
   ],
   "source": [
    "# critical t-value\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "N = 20\n",
    "dof = N - 2\n",
    "t_crit = st.t.ppf(0.975,dof)\n",
    "print(np.round(t_crit,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, how does our actual $t$-statistic compare?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.18\n"
     ]
    }
   ],
   "source": [
    "# calculate the t-statistic\n",
    "r = 0.6\n",
    "\n",
    "t = r * np.sqrt(N-2)/np.sqrt(1-r**2)\n",
    "print(np.round(t,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Since the $t$-statistic is larger than $t_c$, we can reject the null hypothesis that the population correlation is zero ($\\rho$ = 0).\n",
    "\n",
    "## When $\\rho \\neq$ 0:\n",
    "\n",
    "As we saw in the last section, when the true population correlation is not zero, the sampling distribution is not symmetric (like the $z$ or $t$ distributions), and so we cannot use the properties of the normal distribution for hypothesis testing.\n",
    "\n",
    "However, we can transform the sampling distribution of $r$ into something that is normal using the **Fisher-Z Transformation** to obtain the **Fisher-Z statistic**.\n",
    "\n",
    "$$\n",
    "\\text{Fisher-Z} = \\frac{1}{2}ln\\left(\\frac{1+r}{1-r}\\right)\n",
    "$$\n",
    "\n",
    "The Fisher-Z statistic is normally distributed with:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mu_Z &= \\frac{1}{2}ln\\left(\\frac{1+\\rho}{1-\\rho}\\right)\\\\\n",
    "\\sigma_Z &= \\frac{1}{\\sqrt{N-3}} \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "The [table](fisherz) below shows values of $r$ and the corresponding Fisher-Z statistic.\n",
    "\n",
    "```{list-table}\n",
    ":header-rows: 1\n",
    ":name: fisherz\n",
    "\n",
    "* - Correlation Coefficient\n",
    "  - Fisher-Z Statistic\n",
    "* - 0.00\n",
    "  - 0.00\n",
    "* - 0.30\n",
    "  - 0.31\n",
    "* - 0.50\n",
    "  - 0.55\n",
    "* - 0.70\n",
    "  - 0.88\n",
    "* - 0.90\n",
    "  - 1.47\n",
    "* - 0.99\n",
    "  - 2.65\n",
    "```\n",
    "\n",
    "### Confidence Interval on $\\rho$\n",
    "\n",
    "To calculate the confidence interval for correlations (even $\\rho$ = 0), we need to use the Fisher-Z transformation in the same way that we calculated the confidence interval using the $z$-statistic.\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "Z - z_c\\sigma_Z \\leq & \\mu_Z \\leq Z + z_c\\sigma_Z\\\\\n",
    "Z_l \\leq & \\mu_Z \\leq Z_u\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "You can then transform the lower ($Z_l$) and upper ($Z_u$) confidence limits back to correlation using the following expression:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "r_{l,u} & = \\frac{e^{2Z_{l,u}}-1}{e^{2Z_{l,u}}+1}\\\\\n",
    "& = tanh(Z_{l,u})\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Let's look at our previous example and calculate the confidence interval using the Fisher-Z statistic:\n",
    "\n",
    "```{admonition} Question #2\n",
    ":class: tip\n",
    "We have two time series, each of length 20, and they are correlated at $r$ = 0.6. Compute the 95\\% confidence interval for $\\rho$. You can assume both time series are sampled from underlying normal distributions.\n",
    "```\n",
    "We already saw that we can reject the null hypothesis that the population correlation is zero for this example. So, can we get a sense of where the true correlation lies by computing the confidence interval?\n",
    "\n",
    "There is no python function to perform the Fisher-Z transformation, so we have to do this by hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.693 0.243\n"
     ]
    }
   ],
   "source": [
    "r = 0.6\n",
    "N = 20\n",
    "\n",
    "# calculate Fisher-Z statistic and the standard error\n",
    "FZ = 0.5*np.log((1+r)/(1-r))\n",
    "sigma_Z = 1/np.sqrt(N-3)\n",
    "print(np.round(FZ,3),np.round(sigma_Z,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the we have our Fisher-Z statistic and the corresponding standard error, we can compute the critical $z$-value for the 95\\% confidence interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.96\n"
     ]
    }
   ],
   "source": [
    "# critical z-value for two-sided 95% confidence interval\n",
    "z_crit = st.norm.ppf(0.975)\n",
    "print(np.round(z_crit,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as we did with previously with $z$-statistic, we compute the confidence interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upper and lower confidence limits\n",
    "Z_upper = FZ + z_crit*sigma_Z\n",
    "Z_lower = FZ - z_crit*sigma_Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then, we transform the confidence limits back to correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21 0.82\n"
     ]
    }
   ],
   "source": [
    "# transform from Z back to correlation\n",
    "r_upper = np.tanh(Z_upper)\n",
    "r_lower = np.tanh(Z_lower)\n",
    "print(np.round(r_lower,2),np.round(r_upper,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, the population correlation lies between\n",
    "\n",
    "$$\n",
    "0.21 \\leq \\rho \\leq 0.82\n",
    "$$\n",
    "\n",
    "with 95\\% confidence.\n",
    "\n",
    "### Comparing Two Non-Zero Correlations\n",
    "\n",
    "If we want to test the difference between two correlations that are non-zero, we can once again use the Fisher-Z transformation for each and use the fact that $Z$ is normally distributed.\n",
    "\n",
    "Suppose we have two samples of size $N_1$ and $N_2$  which give correlation coefficients of $r_1$ and $r_2$. We test for a significant difference between these correlations by first performing the Fisher-Z transformation for each:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\text{Z_1} & = \\frac{1}{2}ln\\left(\\frac{1+r_1}{1-r_1}\\right)\\\\\n",
    "\\text{Z_2} & = \\frac{1}{2}ln\\left(\\frac{1+r_2}{1-r_2}\\right)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "and then calculating our normal $z$-statistic from the difference of means:\n",
    "\n",
    "$$\n",
    "z = \\frac{Z_1 - Z_2 - \\Delta_{1,2}}{\\sigma_{1,2}}\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "\\Delta_{1,2} = \\mu_1 - \\mu_2\n",
    "$$\n",
    "\n",
    "is the transformed difference you expect (your null hypothesis). If your null hypothesis is that the population correlations of the two samples are equal ($\\rho_1$ = $\\rho_2$), then\n",
    "\n",
    "$$\n",
    "\\Delta_{1,2} = 0\n",
    "$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\sigma_{1,2} & = \\frac{1}{\\sqrt{\\sigma_1^2 + \\sigma_2^2}}\\\\\n",
    "& = \\frac{1}{\\sqrt{\\frac{1}{N_1 - 3} + \\frac{1}{N_2 - 3}}}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
